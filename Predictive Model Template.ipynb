{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Template for you to use develop your model\n",
    "### Copy this template cells to load in the filtered dataset that will be used to do CountVectorizer and TfidfTransformer\n",
    "\n",
    "## REFERENCE NAIVE BAYES MODEL OR SVM NOTEBOOK FOR HELP\n",
    "### DON'T COPY AND PASTE, TRY TO UNDERSTAND WHAT'S GOING ON\n",
    "\n",
    "#### Suggested steps for developing your model\n",
    "1. Load in the filtered title data into a DF --> These cells below\n",
    "2. Create a CountVectorizer and fit_transform it to the x_train dataset --> you will need to import the correct package\n",
    "        a. Save the outputted value --> this is the vectorized matrix of our dataset\n",
    "3. Repeat with the x_test dataset but use transform instead\n",
    "        a. Save as well\n",
    "4. Create a TfidfTransformer and fit_transform it to the vectorized training data from CountVectorizer\n",
    "        a. Save the outputted values --> this is the normalized vectorized maxtrix of our dataset\n",
    "5. Repeat (3) for TfidfTransformer\n",
    "6. Now create and train your model\n",
    "        a. THIS MAY DIFFER FROM HOW NAIVE BAYES AND SVM IS DONE --> DO YOUR RESEARCH\n",
    "        b. In most cases this step will only be a couple of lines\n",
    "7. Analyze the results\n",
    "        a. sklearn's metrics is a good tool\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>filter_title</th>\n",
       "      <th>filter_title_no_stops</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WE WANT TO TALK ABOUT OUR MARRIAGE</td>\n",
       "      <td>we want to talk about our marriage</td>\n",
       "      <td>want talk marriage</td>\n",
       "      <td>People &amp; Blogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Trump Presidency: Last Week Tonight with J...</td>\n",
       "      <td>the trump presidency last week tonight with jo...</td>\n",
       "      <td>trump presidency last week tonight john oliver...</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Racist Superman | Rudy Mancuso, King Bach &amp; Le...</td>\n",
       "      <td>racist superman rudy mancuso king bach lele pons</td>\n",
       "      <td>racist superman rudy mancuso king bach lele pons</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nickelback Lyrics: Real or Fake?</td>\n",
       "      <td>nickelback lyrics real or fake</td>\n",
       "      <td>nickelback lyrics real fake</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I Dare You: GOING BALD!?</td>\n",
       "      <td>i dare you going bald</td>\n",
       "      <td>dare going bald</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                 WE WANT TO TALK ABOUT OUR MARRIAGE   \n",
       "1  The Trump Presidency: Last Week Tonight with J...   \n",
       "2  Racist Superman | Rudy Mancuso, King Bach & Le...   \n",
       "3                   Nickelback Lyrics: Real or Fake?   \n",
       "4                           I Dare You: GOING BALD!?   \n",
       "\n",
       "                                        filter_title  \\\n",
       "0                 we want to talk about our marriage   \n",
       "1  the trump presidency last week tonight with jo...   \n",
       "2   racist superman rudy mancuso king bach lele pons   \n",
       "3                     nickelback lyrics real or fake   \n",
       "4                              i dare you going bald   \n",
       "\n",
       "                               filter_title_no_stops     category_id  \n",
       "0                                 want talk marriage  People & Blogs  \n",
       "1  trump presidency last week tonight john oliver...   Entertainment  \n",
       "2   racist superman rudy mancuso king bach lele pons          Comedy  \n",
       "3                        nickelback lyrics real fake   Entertainment  \n",
       "4                                    dare going bald   Entertainment  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loads the filtered dataset and looks at the first 5 elements\n",
    "\n",
    "df_titles_info = pd.read_csv('./output/US_count_vectorizer_dataset.csv')\n",
    "df_titles_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into inputs(df_x) and outputs(df_y)\n",
    "df_x = df_titles_info['filter_title']\n",
    "df_y = df_titles_info['category_id']\n",
    "\n",
    "# Buckets that we want to map to\n",
    "target_names = list(df_titles_info['category_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the datset 80% training, 20% testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.2, random_state=117)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
