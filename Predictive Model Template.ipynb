{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Template for you to use develop your model\n",
    "### Copy this template cells to load in the filtered dataset that will be used to do CountVectorizer and TfidfTransformer\n",
    "\n",
    "## REFERENCE NAIVE BAYES MODEL OR SVM NOTEBOOK FOR HELP\n",
    "### DON'T COPY AND PASTE, TRY TO UNDERSTAND WHAT'S GOING ON\n",
    "\n",
    "#### Suggested steps for developing your model\n",
    "1. Load in the filtered title data into a DF --> These cells below\n",
    "2. Create a CountVectorizer and fit_transform it to the x_train dataset --> you will need to import the correct package\n",
    "        a. Save the outputted value --> this is the vectorized matrix of our dataset\n",
    "3. Repeat with the x_test dataset but use transform instead\n",
    "        a. Save as well\n",
    "4. Create a TfidfTransformer and fit_transform it to the vectorized training data from CountVectorizer\n",
    "        a. Save the outputted values --> this is the normalized vectorized maxtrix of our dataset\n",
    "5. Repeat (3) for TfidfTransformer\n",
    "6. Now create and train your model\n",
    "        a. THIS MAY DIFFER FROM HOW NAIVE BAYES AND SVM IS DONE --> DO YOUR RESEARCH\n",
    "        b. In most casees this step will only be a couple of lines\n",
    "7. Analyze the results\n",
    "        a. sklearn's metrics is a good tool\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>filter_title</th>\n",
       "      <th>description</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WE WANT TO TALK ABOUT OUR MARRIAGE</td>\n",
       "      <td>we want to talk about our marriage</td>\n",
       "      <td>shantells channel httpswwwyoutubecomshantellma...</td>\n",
       "      <td>People &amp; Blogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Trump Presidency: Last Week Tonight with J...</td>\n",
       "      <td>the trump presidency last week tonight with jo...</td>\n",
       "      <td>one year after the presidential election john ...</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Racist Superman | Rudy Mancuso, King Bach &amp; Le...</td>\n",
       "      <td>racist superman rudy mancuso king bach lele pons</td>\n",
       "      <td>watch my previous video ▶ nnsubscribe ► httpsw...</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nickelback Lyrics: Real or Fake?</td>\n",
       "      <td>nickelback lyrics real or fake</td>\n",
       "      <td>today we find out if link is a nickelback amat...</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I Dare You: GOING BALD!?</td>\n",
       "      <td>i dare you going bald</td>\n",
       "      <td>i know its been a while since we did this show...</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                 WE WANT TO TALK ABOUT OUR MARRIAGE   \n",
       "1  The Trump Presidency: Last Week Tonight with J...   \n",
       "2  Racist Superman | Rudy Mancuso, King Bach & Le...   \n",
       "3                   Nickelback Lyrics: Real or Fake?   \n",
       "4                           I Dare You: GOING BALD!?   \n",
       "\n",
       "                                        filter_title  \\\n",
       "0                 we want to talk about our marriage   \n",
       "1  the trump presidency last week tonight with jo...   \n",
       "2   racist superman rudy mancuso king bach lele pons   \n",
       "3                     nickelback lyrics real or fake   \n",
       "4                              i dare you going bald   \n",
       "\n",
       "                                         description     category_id  \n",
       "0  shantells channel httpswwwyoutubecomshantellma...  People & Blogs  \n",
       "1  one year after the presidential election john ...   Entertainment  \n",
       "2  watch my previous video ▶ nnsubscribe ► httpsw...          Comedy  \n",
       "3  today we find out if link is a nickelback amat...   Entertainment  \n",
       "4  i know its been a while since we did this show...   Entertainment  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loads the filtered dataset and looks at the first 5 elements\n",
    "\n",
    "df_titles_info = pd.read_csv('./output/US_count_vectorizer_dataset.csv')\n",
    "df_titles_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into inputs(df_x) and outputs(df_y)\n",
    "df_x = df_titles_info['filter_title']\n",
    "df_y = df_titles_info['category_id']\n",
    "\n",
    "# Buckets that we want to map to\n",
    "target_names = list(df_titles_info['category_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the datset 80% training, 20% testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.2, random_state=117)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
